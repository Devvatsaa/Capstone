{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Capstone Project Report\n",
        "\n",
        "Predicting Yield in Semiconductor Manufacturing\n",
        "\n",
        "Domain: Semiconductor Manufacturing Process"
      ],
      "metadata": {
        "id": "7qLNtqLdzfSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Context\n",
        "\n",
        "A complex modern semiconductor manufacturing process is normally under constant surveillance via the monitoring of signal variables collected from sensors and/or process measurement points. However, not all of these signals are equally valuable in a specific monitoring system. The measured signals contain a combination of useful information, irrelevant information, and noise. Engineers typically have a much larger number of signals than are required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most relevant signals. Process Engineers may then use these signals to determine key factors contributing to yield excursions downstream in the process, enabling an increase in process throughput, decreased time to learning, and reduced per unit production costs. These signals can be used as features to predict the yield type. By analyzing and trying out different combinations of features, essential signals that impact the yield type can be identified."
      ],
      "metadata": {
        "id": "tfNwtUV_zk9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Description\n",
        "\n",
        "The dataset, sensor-data.csv, consists of 1567 examples, each with 591 features. Each example represents a single production entity with associated measured features, and the labels represent a simple pass/fail yield for in-house line testing. The target column “-1” corresponds to a pass, and “1” corresponds to a fail.\n",
        "\n"
      ],
      "metadata": {
        "id": "OcvUCf0tzvMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Project Objective\n",
        "\n",
        "The objective of this project is to build a classifier to predict the Pass/Fail yield of a particular process entity and analyze whether all the features are required to build the model or not."
      ],
      "metadata": {
        "id": "-KVBQ4B0zywf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Steps and Tasks\n",
        "\n",
        "Step 1: Import and Explore the Data\n",
        "\n",
        "Task 1.1: Import the data from sensor-data.csv using pandas.\n",
        "\n",
        "Task 1.2: Inspect the first few rows of the dataset to understand its structure and contents.\n",
        "\n",
        "Task 1.3: Check for the presence of any missing values.\n",
        "\n",
        "Task 1.4: Explore the basic statistics of the dataset (mean, median, standard deviation, etc.).\n"
      ],
      "metadata": {
        "id": "mzSzj2muz1pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/uci-secom.csv')\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(f\"Missing values in each column:\\n{missing_values[missing_values > 0]}\")\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = data.select_dtypes(include=['number']).columns\n",
        "non_numeric_cols = data.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "# Fill missing values in numeric columns with the mean\n",
        "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
        "\n",
        "# Fill missing values in non-numeric columns with the mode\n",
        "for col in non_numeric_cols:\n",
        "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
        "\n",
        "# Verify there are no more missing values\n",
        "missing_values_after = data.isnull().sum()\n",
        "print(f\"Missing values after filling:\\n{missing_values_after[missing_values_after > 0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsZquWpdz_15",
        "outputId": "cddfffb8-17d5-4930-f0d5-3375596e9242"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "0       6\n",
            "1       7\n",
            "2      14\n",
            "3      14\n",
            "4      14\n",
            "       ..\n",
            "585     1\n",
            "586     1\n",
            "587     1\n",
            "588     1\n",
            "589     1\n",
            "Length: 538, dtype: int64\n",
            "Missing values after filling:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Data Cleansing\n",
        "\n",
        "Data cleansing is a crucial step to ensure that the data is accurate and ready for analysis. This step involves handling missing values, removing irrelevant attributes, and making necessary modifications to the data.\n",
        "\n",
        "Task 2.1: Handle Missing Values\n",
        "\n",
        "Identify columns with missing values.\n",
        "\n",
        "Decide on an appropriate strategy to handle missing values (e.g., mean/mode/median imputation, or removing rows/columns)."
      ],
      "metadata": {
        "id": "UFRACgoW1lo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(f\"Missing values in each column:\\n{missing_values}\")\n",
        "\n",
        "# Display basic statistics of the dataset\n",
        "print(data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Ca2qcW1qdr",
        "outputId": "4124d95e-184d-4a1c-d748-8cf996340e9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "Time         0\n",
            "0            0\n",
            "1            0\n",
            "2            0\n",
            "3            0\n",
            "            ..\n",
            "586          0\n",
            "587          0\n",
            "588          0\n",
            "589          0\n",
            "Pass/Fail    0\n",
            "Length: 592, dtype: int64\n",
            "                 0            1            2            3            4  \\\n",
            "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000   \n",
            "mean   3014.452896  2495.850231  2200.547318  1396.376627     4.197013   \n",
            "std      73.480613    80.227793    29.380932   439.712852    56.103066   \n",
            "min    2743.240000  2158.750000  2060.660000     0.000000     0.681500   \n",
            "25%    2966.665000  2452.885000  2181.099950  1083.885800     1.017700   \n",
            "50%    3011.840000  2498.910000  2200.955600  1287.353800     1.317100   \n",
            "75%    3056.540000  2538.745000  2218.055500  1590.169900     1.529600   \n",
            "max    3356.350000  2846.440000  2315.266700  3715.041700  1114.536600   \n",
            "\n",
            "            5            6            7            8            9  ...  \\\n",
            "count  1567.0  1567.000000  1567.000000  1567.000000  1567.000000  ...   \n",
            "mean    100.0   101.112908     0.121822     1.462862    -0.000841  ...   \n",
            "std       0.0     6.209271     0.008936     0.073849     0.015107  ...   \n",
            "min     100.0    82.131100     0.000000     1.191000    -0.053400  ...   \n",
            "25%     100.0    97.937800     0.121100     1.411250    -0.010800  ...   \n",
            "50%     100.0   101.492200     0.122400     1.461600    -0.001300  ...   \n",
            "75%     100.0   104.530000     0.123800     1.516850     0.008400  ...   \n",
            "max     100.0   129.252200     0.128600     1.656400     0.074900  ...   \n",
            "\n",
            "               581          582          583          584          585  \\\n",
            "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000   \n",
            "mean     97.934373     0.500096     0.015318     0.003847     3.067826   \n",
            "std      54.936224     0.003403     0.017174     0.003719     3.576891   \n",
            "min       0.000000     0.477800     0.006000     0.001700     1.197500   \n",
            "25%      91.549650     0.497900     0.011600     0.003100     2.306500   \n",
            "50%      97.934373     0.500200     0.013800     0.003600     2.757700   \n",
            "75%      97.934373     0.502350     0.016500     0.004100     3.294950   \n",
            "max     737.304800     0.509800     0.476600     0.104500    99.303200   \n",
            "\n",
            "               586          587          588          589    Pass/Fail  \n",
            "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000  \n",
            "mean      0.021458     0.016475     0.005283    99.670066    -0.867262  \n",
            "std       0.012354     0.008805     0.002866    93.861936     0.498010  \n",
            "min      -0.016900     0.003200     0.001000     0.000000    -1.000000  \n",
            "25%       0.013450     0.010600     0.003300    44.368600    -1.000000  \n",
            "50%       0.020500     0.014800     0.004600    72.023000    -1.000000  \n",
            "75%       0.027600     0.020300     0.006400   114.749700    -1.000000  \n",
            "max       0.102800     0.079900     0.028600   737.304800     1.000000  \n",
            "\n",
            "[8 rows x 591 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task** 2.2: Remove Constant Features\n",
        "Remove features that have the same value in all rows."
      ],
      "metadata": {
        "id": "4Nmufuqd2CJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove constant features\n",
        "constant_features = [col for col in data.columns if data[col].nunique() == 1]\n",
        "data.drop(columns=constant_features, inplace=True)\n",
        "print(f\"Constant features dropped: {constant_features}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYPJyYaX2Fin",
        "outputId": "dbe4de9a-50c6-4063-a6a0-3ada5ff5438a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant features dropped: ['5', '13', '42', '49', '52', '69', '97', '141', '149', '178', '179', '186', '189', '190', '191', '192', '193', '194', '226', '229', '230', '231', '232', '233', '234', '235', '236', '237', '240', '241', '242', '243', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '276', '284', '313', '314', '315', '322', '325', '326', '327', '328', '329', '330', '364', '369', '370', '371', '372', '373', '374', '375', '378', '379', '380', '381', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '414', '422', '449', '450', '451', '458', '461', '462', '463', '464', '465', '466', '481', '498', '501', '502', '503', '504', '505', '506', '507', '508', '509', '512', '513', '514', '515', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2.3: Remove Duplicate Rows\n",
        "Remove any duplicate rows in the dataset."
      ],
      "metadata": {
        "id": "lhELCBAF5paC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows\n",
        "data.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "lVdA3kDN5qcF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2.4: Identify and Remove Outliers\n",
        "Use statistical methods or visualization techniques to identify outliers.\n",
        "Remove or handle outliers based on the chosen method."
      ],
      "metadata": {
        "id": "WJUguF0N5sHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the IQR method to identify outliers\n",
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Filtering out the outliers\n",
        "data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Display the shape of the data after outlier removal\n",
        "print(f\"Data shape after outlier removal: {data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVbQ1hCn5uFn",
        "outputId": "9273d7a0-a852-4d16-bb34-732fcf194f08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape after outlier removal: (0, 475)\n"
          ]
        }
      ]
    }
  ]
}